{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import pickle\n",
    "import glob\n",
    "from torch.utils.data import  DataLoader\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "#cudnn.fastest = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os.path import expanduser\n",
    "\n",
    "data_file = expanduser(\"../datasets/sem3d_rgbd_depthlim5_ims/semantic3Dsplatting.mat\")\n",
    "#data_file = \"/home/linhe979/3dPointCloud/sem3d_rgbd_depthlim5_ims/semantic3Dsplatting.mat\"\n",
    "matfile = scio.loadmat(data_file)\n",
    "name = matfile[\"images\"][\"name\"][0][0][0]  # should give a list of names\n",
    "image_sizes = matfile[\"images\"][\"size\"][0][0][0]\n",
    "istrain = matfile[\"images\"][\"set\"][0][0][0]\n",
    "training_set = [i for i in range(len(istrain)) if istrain[i] > 0]\n",
    "validation_set = [i for i in range(len(istrain)) if istrain[i] == 0]\n",
    "imdb = {\"name\": name, \"image_sizes\": image_sizes, \"training_set\": training_set, \"validation_set\":validation_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class IMDBReader(object):\n",
    "    \n",
    "    def __init__(self, streams: list, imdb_file, stat_file, suffix, fetch_range=None):\n",
    "   \n",
    "        self.streams_db  = ['color', 'depth', 'normal', 'label']\n",
    "        self.streams = streams\n",
    "    \n",
    "        assert set(self.streams).issubset(set(self.streams_db)), \"The input streams should refer to {}\".format(self.streams_db)\n",
    "        \n",
    "        self.imdb = self.loadIMDBFile(imdb_file)\n",
    "\n",
    "        print(\"self.imdb validation_set: \", self.imdb['validation_set'])\n",
    "        self.stat = self.loadStatFile(stat_file)\n",
    "        self.suffix = suffix  # '.png' or '.jpg' etc\n",
    "        \n",
    "        self.attributes = ['rgb', 'shape', 'dtype']\n",
    "        self.path_names = ['color_path', 'djet_path', 'normal_path', 'label_path']\n",
    "        \n",
    "        path_to_color = '../datasets/sem3d_rgbd_depthlim5_ims/rgb/'    # need to change to Rel Path.\n",
    "        path_to_depth = '../datasets/sem3d_rgbd_depthlim5_ims/djet/'\n",
    "        path_to_normal = '../datasets/sem3d_rgbd_depthlim5_ims/normals/'\n",
    "        path_to_label = '../datasets/sem3d_rgbd_depthlim5_ims/labels/'\n",
    "        self.paths = {self.streams_db[0]: path_to_color, \n",
    "                 self.streams_db[1]: path_to_depth, \n",
    "                 self.streams_db[2]: path_to_normal, \n",
    "                 self.streams_db[3]: path_to_label,\n",
    "                }\n",
    "        \n",
    "        \n",
    "        self.expected_num_of_files = len(glob.glob1(self.paths[self.streams[0]], '*' + self.suffix))\n",
    "        \n",
    "        #check if the number of imgaes with samma extension is same for all streams\n",
    "        hasSameNumOfFiles = all([len(glob.glob1(self.paths[self.streams[i]], '*' + self.suffix)) == self.expected_num_of_files for i in range(len(self.streams)) ])\n",
    "        assert hasSameNumOfFiles, \",\\n\".join([\"{} folder has {} files\".format(self.streams[i], len(glob.glob1(self.paths[self.streams[i]], '*' + self.suffix))) for i in range(len(self.streams))])\n",
    "        \n",
    "        \n",
    "        self.num_of_imgs = len(self.imdb['name'])\n",
    "        self.fetch_range = fetch_range\n",
    "        self.indices = list(range(self.num_of_imgs))\n",
    "        if self.fetch_range:\n",
    "            assert isinstance(self.fetch_range, tuple), \"The fetch_range should have type 'tuple'\"\n",
    "            assert self.fetch_range[1] < self.num_of_imgs, \"fetch_range out of range, total number of existing files: {}\".format(self.num_of_imgs)\n",
    "            self.all_indices = list(range(self.num_of_imgs))\n",
    "            self.indices = self.all_indices[slice(*self.fetch_range)]\n",
    "\n",
    "        self.images = {}\n",
    "    \n",
    "    \n",
    "    def loadIMDBFile(self, imdb_file):\n",
    "        if \".mat\" in imdb_file:\n",
    "            matfile = scio.loadmat(imdb_file)\n",
    "            name = matfile[\"images\"][\"name\"][0][0][0]  # should give a list of names\n",
    "            image_sizes = matfile[\"images\"][\"size\"][0][0][0]\n",
    "            istrain = matfile[\"images\"][\"set\"][0][0][0]\n",
    "            training_set = [i for i in range(len(istrain)) if istrain[i] > 0]\n",
    "            validation_set = [i for i in range(len(istrain)) if istrain[i] == 0]\n",
    "            imdb = {\"name\": name, \"image_sizes\": image_sizes, \"training_set\": training_set, \"validation_set\":validation_set}\n",
    "            return imdb\n",
    "        else:\n",
    "            imdb = pickle.load( open( imdb_file, \"rb\" ) )\n",
    "            return imdb\n",
    "\n",
    "\n",
    "    def loadStatFile(self, stat_file):\n",
    "        if \".mat\" in stat_file:\n",
    "            stat = scio.loadmat(stat_file)\n",
    "            return stat\n",
    "        else:\n",
    "            imdb = pickle.load( open( stat_file, \"rb\" ) )\n",
    "            return stat\n",
    "    \n",
    "    '''\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        self.images = {}  # remove the buffer from previous data fetch\n",
    "        \n",
    "        if(isinstance(idx, int)):\n",
    "            return self._loadImage(idx)\n",
    "        \n",
    "        elif(isinstance(idx, slice)):  # enable slicing indexing\n",
    "            idx_list = idx.indices(self.expected_num_of_files)  # get (start, stop, step)\n",
    "            return self._loadImage([i for i in range(*idx_list)])\n",
    "            \n",
    "        elif(isinstance(idx, str)):            \n",
    "            ind = np.where(self.imdb['name'] == np.array([idx], dtype='<U38'))[0][0]  \n",
    "            ind = ind.item()\n",
    "            return self._loadImage(ind)\n",
    "    '''\n",
    "    \n",
    "    def loadImage(self, idx):\n",
    "        self.images = {}  # remove the buffer from previous data fetch\n",
    "        \n",
    "        selected_indices = self.makeToIndices(idx)\n",
    "        \n",
    "        img_names = [self.imdb['name'][selected_indices[i]][0] + self.suffix for i in range(len(selected_indices))]\n",
    "        \n",
    "        for stream_name in self.streams:\n",
    "            if stream_name == 'label':\n",
    "                imgs = [cv2.imread(self.paths[stream_name] + '/' + img_names[i], 0) for i in range(len(img_names))]\n",
    "                self.images[stream_name] = imgs\n",
    "\n",
    "            elif stream_name != 'label':\n",
    "                imgs = [cv2.imread(self.paths[stream_name] + '/' + img_names[i]) for i in range(len(img_names))]\n",
    "                imgs_reshaped = [imgs[i].transpose((2, 0, 1)) for i in range(len(imgs))]  #From N x H x W x C  To  N x C x H x W for each image\n",
    "                self.images[stream_name] = imgs_reshaped\n",
    "            \n",
    "            \n",
    "               \n",
    "        '''\n",
    "        for i in range(len(indices)):\n",
    "            img_name = self.imdb['name'][indices[i]][0]\n",
    "            img_name += self.suffix\n",
    "            \n",
    "            streams_img = [cv2.imread(self.paths[self.streams[i]] + '/' + img_name) for i in range(len(self.streams))] \n",
    "\n",
    "            data = {}  \n",
    "            #check if all streams have rgb channels for an image\n",
    "            assert all(len(streams_img[s].shape)==3 for s in range(len(streams_img))), \"Not all streams of {} have rgb channels!\".format(img.name)\n",
    "            \n",
    "            for i in range(len(self.streams)):\n",
    "                data[self.streams[i]] = self._getImageInfo(streams_img[i])\n",
    "            \n",
    "            self.images.append(data)\n",
    "        '''\n",
    "        return self.images   # {'stream1': (N x C x H x W), 'stream2': (N x C x H x W), .....}\n",
    "        \n",
    "\n",
    "    def setRange(self, newRange):\n",
    "        assert isinstance(newRange, tuple), \"The range input should have type 'tuple'\"\n",
    "        assert newRange[1] - 1 > self.num_of_imgs, \"fetch_range out of range, total number of existing files: {}\".format(self.num_of_imgs)\n",
    "\n",
    "        self.fetch_range = newRange\n",
    "        self.indices = self.all_indices[slice(*self.fetch_range)]\n",
    "\n",
    "    def makeToIndices(self, idx):\n",
    "        list_of_index = []\n",
    "        if(isinstance(idx, int)):\n",
    "            list_of_index = [self.indices[idx]]\n",
    "        elif(isinstance(idx, slice)):\n",
    "            list_of_index = self.indices[idx]\n",
    "        #elif(isinstance(idx, str)):\n",
    "        #   pass\n",
    "        return list_of_index\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class Sem3DIMGDataset(Dataset):\n",
    "\n",
    "    def __init__(self, params, training=True, transform=None): \n",
    "        \n",
    "        self.training = training\n",
    "        #self.scale_range = scale_range\n",
    "        _type = \"TRAIN\" if training else \"TEST\"\n",
    "        \n",
    "        self.dset = IMDBReader(params.streams, params.imdb_file, params.stat_file, params.suffix, params.fetch_range)\n",
    "        #print(\"training: \", self.dset.imdb['training_set'])\n",
    "        self.inds = self.dset.imdb[\"training_set\"] if self.training else self.dset.imdb[\"validation_set\"]\n",
    "        self.pid = os.getpid()\n",
    "        self.rng = np.random.RandomState()\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dset.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dset.loadImage(idx)\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        #self.length = len(sample[params.streams[0]])\n",
    "        #if(self.length == 1):\n",
    "            #sample.update({i: sample[i][0] for i in params.streams})\n",
    " \n",
    "        return sample\n",
    "        \n",
    "        #elif(isinstance(idx, str)):            \n",
    "        #    ind = np.where(self.dset.imdb['name'] == np.array([idx], dtype='<U38'))[0][0]  \n",
    "        #    ind = ind.item()\n",
    "        #    return self.dset.loadImage(ind)\n",
    "        \n",
    "\n",
    "    def setRange(self, newRange):\n",
    "        self.dset.setRange(newRange)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        #sample has type list, created from LoadImage().\n",
    "        keys = list(sample.keys())\n",
    "\n",
    "        for i in range(len(sample)):\n",
    "            #sample.update({keys[i]: [torch.from_numpy(j) for j in sample[keys[i]]]})\n",
    "            \n",
    "            if(len(sample[keys[i]]) == 1): \n",
    "                #sample.update({keys[i]: torch.from_numpy(sample[keys[i]][0])})\n",
    "                if keys[i] == 'label': \n",
    "                    converted = torch.from_numpy(sample[keys[i]][0]).long()\n",
    "\n",
    "                else:\n",
    "                    converted = torch.from_numpy(sample[keys[i]][0]).float()\n",
    "                sample.update({keys[i]: converted})\n",
    "            else:\n",
    "                #sample.update({keys[i]: [torch.from_numpy(j).float() for j in sample[keys[i]]]})\n",
    "                if keys[i] == 'label':\n",
    "                    converted = [torch.from_numpy(j).long() for j in sample[keys[i]]]\n",
    "                else:\n",
    "                    converted = [torch.from_numpy(j).float() for j in sample[keys[i]]]\n",
    "                sample.update({keys[i]: converted})\n",
    "        return sample\n",
    "\n",
    "#normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    " #F.normalize(tensor, self.mean, self.std)\n",
    "#sample[name] = F.normalize(sample[name], [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "class ToNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        # after ToTensor(), sample['bla'] is a Tensor now\n",
    "        keys = list(sample.keys())\n",
    "        if 'label' in keys: \n",
    "            keys.remove('label')     #labels will NOT be normalized\n",
    "            \n",
    "        for name in keys:\n",
    "            tensor = sample[name]\n",
    "            for t, m, s in zip(tensor, self.mean, self.std):\n",
    "                t.sub_(m).div_(s)\n",
    "            sample.update({name: tensor})\n",
    "\n",
    "        return sample\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Hyperparams(object):\n",
    "    def __init__(self):\n",
    "        self.streams = ['color','label'] # now using only one stream for training!!!\n",
    "        self.imdb_file = '../datasets/sem3d_rgbd_depthlim5_ims/semantic3Dsplatting.mat'\n",
    "        self.stat_file = '../datasets/sem3d_rgbd_depthlim5_ims/semantic3Dsplatting-stat.mat'\n",
    "        self.fetch_range = (1,1003,600)  # (start, end, step)\n",
    "        self.suffix = '.png'\n",
    "        self.num_workers = 2\n",
    "        self.batch_size = 2\n",
    "        self.gpu_id = []             # GPU ID. -1 == use any available GPU\n",
    "        self.lr = 0.0001\n",
    "        self.loss_func = torch.nn.NLLLoss(ignore_index=255, size_average=True)\n",
    "        self.momentum = 0.99\n",
    "        self.pretrained=None\n",
    "        \n",
    "    def get_optimizer(self, model):\n",
    "        self.optimizer = torch.optim.SGD(model.parameters(), lr=self.lr, momentum=self.momentum, weight_decay=0)\n",
    "        return self.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#params = Hyperparams()\n",
    "#my_dataset = Sem3DIMGDataset(params, transform=ToTensor())\n",
    "#dataloader = DataLoader(my_dataset, batch_size=2, shuffle=True, num_workers=4)\n",
    "#for i, sample in enumerate(dataloader):\n",
    "#    print(\"sample type:\", type(sample))\n",
    "#    print(\"i: \", i, \" , label size: \", sample['label'].size() )\n",
    "#print(\"len(my_dataset): \", len(my_dataset))\n",
    "\n",
    "\n",
    "#cv2.imshow(\"out\", one_label)\n",
    "#k = cv2.waitKey(0)\n",
    "#if k == ord('s'):        # wait for pressing 's'\n",
    "#    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "#ame_db = glob.glob(\"../datasets/sem3d_rgbd_depthlim5_ims/labels/*.png\")\n",
    "#n_classes = 0\n",
    "#for name in name_db:\n",
    "#    img = cv2.imread(name,0)\n",
    "#    num_of_classes = len(set([img.item(i,j) for i in range(500) for j in range(500)]))\n",
    "#    n_classes = num_of_classes if num_of_classes > n_classes else n_classes\n",
    "    \n",
    "#print(\"n_classes: \", n_classes) \n",
    "# 10 classes in total !!!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "vgg16_pretrained = torchvision.models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.imdb validation_set:  []\n",
      "output shape: torch.Size([2, 9, 500, 500])\n",
      "------------------------------batch_loss-------------------------------  ->  5.3384623527526855\n",
      "0  running_loss:  5.3384623527526855\n",
      "output shape: torch.Size([2, 9, 500, 500])\n",
      "------------------------------batch_loss-------------------------------  ->  4.756173610687256\n",
      "1  running_loss:  4.756173610687256\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "def main(args: Hyperparams):\n",
    "    num_streams = len(args.streams)-1 if 'label' in args.streams else len(args.streams)\n",
    "    tr_dset = Sem3DIMGDataset(args, training=True, transform=transforms.Compose([\n",
    "            ToTensor(),\n",
    "            ToNormalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "]))\n",
    "    tr_loader = DataLoader(tr_dset, num_workers=args.num_workers, shuffle=True, batch_size=args.batch_size)\n",
    "    #print(\"dataloader length:\", len(tr_loader))\n",
    "    model = DeePr3essNet(pretrained_path=vgg16_pretrained, num_modalities=num_streams, use_cuda=False)\n",
    "    #model = model.cuda()\n",
    "    optimizer = args.get_optimizer(model)\n",
    "    loss_func = args.loss_func\n",
    "    \n",
    "\n",
    "    for epoch in range(2):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(tr_loader):\n",
    "            #print(\"i : \", i)\n",
    "            keys = list(data.keys())\n",
    "            \n",
    "            if 'label' in keys:\n",
    "                keys.remove('label')\n",
    "            else:\n",
    "                raise ValueError(\"There is no label in dataloader\")\n",
    "            #print(keys)\n",
    "            \n",
    "            '''\n",
    "            #--------------------------------------loss method 1-----------------------------------------------\n",
    "            \n",
    "            batch_loss = 0\n",
    "            batch_size = len(data[keys[0]])# batch_size is not necessarily the args.batch_size, think of mod() operation\n",
    "            for k in range(batch_size):\n",
    "                inputs = [Variable(data[name][k].unsqueeze(0), requires_grad=True) for name in keys]\n",
    "                target = data['label'][k]\n",
    "                target = Variable(target.unsqueeze(0), requires_grad=False)\n",
    "\n",
    "                output = model(inputs)\n",
    "                logsoftmax = torch.nn.LogSoftmax(dim=1)\n",
    "                loss = loss_func(logsoftmax(output), target)\n",
    "                print('------------------------------loss-------------------------------  -> ', loss.data[0])\n",
    "                batch_loss += loss\n",
    "            batch_loss /= 2\n",
    "            '''\n",
    "            '''\n",
    "            #--------------------------------------loss method 2-----------------------------------------------\n",
    "            \n",
    "            batch_loss = 0\n",
    "            batch_size = len(data[keys[0]])# batch_size is not necessarily the args.batch_size, think of mod() operation\n",
    "            output = []\n",
    "            targets = Variable(data['label'].cuda(), requires_grad=False)\n",
    "            for k in range(batch_size):\n",
    "                inputs = [Variable(data[name][k].unsqueeze(0).cuda(), requires_grad=True) for name in keys]\n",
    "                #target = data['label'][k]\n",
    "                #target = Variable(target.unsqueeze(0), requires_grad=False)\n",
    "                res = model(inputs)\n",
    "                output.append(res.squeeze(0))\n",
    "            outputs = torch.stack(output, dim=0)\n",
    "            logsoftmax = torch.nn.LogSoftmax(dim=1)\n",
    "            batch_loss = loss_func(logsoftmax(outputs), targets)\n",
    "            print('------------------------------batch_loss-------------------------------  -> ', batch_loss.data[0])\n",
    "            '''\n",
    "            \n",
    "             #--------------------------------------loss method 3-----------------------------------------------\n",
    "            \n",
    "            batch_loss = 0\n",
    "            #targets = Variable(data['label'].cuda(), requires_grad=False)\n",
    "            targets = Variable(data['label'], requires_grad=False)\n",
    "            \n",
    "            #inputs = [Variable(data[name].cuda(), requires_grad=True) for name in keys]\n",
    "            inputs = [Variable(data[name], requires_grad=True) for name in keys]\n",
    "            \n",
    "            #print(\"inputs color shape:\", inputs[0].size())\n",
    "\n",
    "            #print(\"target shape:\", targets.size())\n",
    "            output = model(inputs)\n",
    "            print(\"output shape:\", output.size())\n",
    "            \n",
    "            logsoftmax = torch.nn.LogSoftmax(dim=1)\n",
    "            batch_loss = loss_func(logsoftmax(output), targets)\n",
    "            print('------------------------------batch_loss-------------------------------  -> ', batch_loss.data[0])\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "                        \n",
    "            #time.sleep(5)\n",
    "            running_loss += batch_loss\n",
    "        print(epoch,\" running_loss: \", running_loss.data[0])\n",
    "\n",
    "params = Hyperparams()\n",
    "main(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "def get_upsampling_weight(in_channels, out_channels, kernel_size):\n",
    "    \"\"\"Make a 2D bilinear kernel suitable for upsampling\"\"\"\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),\n",
    "                      dtype=np.float64)\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return torch.from_numpy(weight).float()\n",
    "\n",
    "\n",
    "class DeePr3essNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class=9, pretrained_path=None, num_modalities=1, use_cuda=False):\n",
    "        super(DeePr3essNet, self).__init__()\n",
    "        self.use_cuda = use_cuda\n",
    "        \n",
    "        self.nets = []\n",
    "        for i in range(0,num_modalities):\n",
    "            self.nets.append(FCN8s(n_class,pretrained_path))\n",
    "\n",
    "        self.upscore8 = nn.ConvTranspose2d(  \n",
    "            n_class, n_class, 16, stride=8, bias=False)\n",
    "\n",
    "    \n",
    "    def forward(self, x):  \n",
    "        assert len(x) == len(self.nets) \n",
    "        h = 0\n",
    "        for i,net in enumerate(self.nets):\n",
    "            if self.use_cuda:\n",
    "                net = net.cuda()\n",
    "            res = net(x[i])\n",
    "            h = h + res  #fusion\n",
    "\n",
    "        h = self.upscore8(h)\n",
    "        #print(\"upscore8 output size : \", h.data.size(), ' -> 1')\n",
    "        \n",
    "        h = h[:, :, 2:2 + x[0].size()[2], 2:2 + x[0].size()[3]].contiguous()\n",
    "        #print(\"h[2 : 2+input.size()] output size : \", h.data.size(), ' -> 1')\n",
    "        return h\n",
    "\n",
    "\n",
    "class FCN8s(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class=9, pretrained_path=None):\n",
    "        super(FCN8s, self).__init__()\n",
    "        # conv1\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=70)\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/2\n",
    "\n",
    "        # conv2\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/4\n",
    "\n",
    "        # conv3\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/8\n",
    "\n",
    "        # conv4\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/16\n",
    "\n",
    "        # conv5\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_2 = nn.ReLU(inplace=True)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_3 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/32\n",
    "\n",
    "        # fc6\n",
    "        self.fc6 = nn.Conv2d(512, 4096, 7)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.drop6 = nn.Dropout2d()\n",
    "\n",
    "        # fc7\n",
    "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.drop7 = nn.Dropout2d()\n",
    "\n",
    "        self.score_fr = nn.Conv2d(4096, n_class, 1)\n",
    "        self.score_pool3 = nn.Conv2d(256, n_class, 1)\n",
    "        self.score_pool4 = nn.Conv2d(512, n_class, 1)\n",
    "\n",
    "        self.upscore2 = nn.ConvTranspose2d(\n",
    "            n_class, n_class, 4, stride=2, bias=False)\n",
    "        self.upscore8 = nn.ConvTranspose2d(\n",
    "            n_class, n_class, 16, stride=8, bias=False)\n",
    "        self.upscore_pool4 = nn.ConvTranspose2d(\n",
    "            n_class, n_class, 4, stride=2, bias=False)\n",
    "\n",
    "        self._initialize_weights()\n",
    "        if pretrained_path is not None:\n",
    "            self.copy_params_from_vgg16(pretrained_path)\n",
    "            torch.nn.init.xavier_uniform(self.score_fr.weight)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.zero_()\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                assert m.kernel_size[0] == m.kernel_size[1]\n",
    "                initial_weight = get_upsampling_weight(\n",
    "                    m.in_channels, m.out_channels, m.kernel_size[0])\n",
    "                m.weight.data.copy_(initial_weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        #print(\"input size : \", h.data.size())\n",
    "\n",
    "        h = self.relu1_1(self.conv1_1(h))\n",
    "        #print(\"conv1_1 PADDING=70 output size : \", h.data.size(), \" -> 1\")\n",
    "\n",
    "        h = self.relu1_2(self.conv1_2(h))\n",
    "        h = self.pool1(h)\n",
    "        #print(\"conv1 output size : \", h.data.size(), \" -> 1/2\")\n",
    "\n",
    "        h = self.relu2_1(self.conv2_1(h))\n",
    "        h = self.relu2_2(self.conv2_2(h))\n",
    "        h = self.pool2(h)\n",
    "        #print(\"conv2 output size : \", h.data.size(), \" -> 1/4\")\n",
    "\n",
    "        h = self.relu3_1(self.conv3_1(h))\n",
    "        h = self.relu3_2(self.conv3_2(h))\n",
    "        h = self.relu3_3(self.conv3_3(h))\n",
    "        h = self.pool3(h)\n",
    "        pool3 = h  # 1/8\n",
    "        #print(\"conv3 output size : \", h.data.size(), \" -> 1/8\")\n",
    "\n",
    "        h = self.relu4_1(self.conv4_1(h))\n",
    "        h = self.relu4_2(self.conv4_2(h))\n",
    "        h = self.relu4_3(self.conv4_3(h))\n",
    "        h = self.pool4(h)\n",
    "        pool4 = h  # 1/16\n",
    "        #print(\"conv4 output size : \", h.data.size(), \" -> 1/16\")\n",
    "\n",
    "        h = self.relu5_1(self.conv5_1(h))\n",
    "        h = self.relu5_2(self.conv5_2(h))\n",
    "        h = self.relu5_3(self.conv5_3(h))\n",
    "        h = self.pool5(h)\n",
    "        #print(\"conv5 output size : \", h.data.size(), \" -> 1/32\")\n",
    "\n",
    "        h = self.relu6(self.fc6(h))\n",
    "        h = self.drop6(h)\n",
    "        #print(\"fc6 output size : \", h.data.size())\n",
    "\n",
    "        h = self.relu7(self.fc7(h))\n",
    "        h = self.drop7(h)\n",
    "        #print(\"fc7 output size : \", h.data.size())\n",
    "\n",
    "        h = self.score_fr(h)\n",
    "        #print(\"score_fr output size : \", h.data.size())\n",
    "\n",
    "        h = self.upscore2(h)\n",
    "        upscore2 = h  # 1/16\n",
    "        #print(\"upscore2 output size : \", h.data.size())\n",
    "\n",
    "        h = self.score_pool4(pool4)\n",
    "        #print(\"score_pool4(pool4) output size : \", h.data.size())\n",
    "\n",
    "        h = h[:, :, 5:5 + upscore2.size()[2], 5:5 + upscore2.size()[3]]\n",
    "        #print(\"score_pool4c = h[5 : 5+upscore2.size()] output size : \", h.data.size(), ' -> 1/16')\n",
    "        score_pool4c = h  # 1/16\n",
    "\n",
    "        h = upscore2 + score_pool4c  # 1/16\n",
    "        #print(\"upscore2 + score_pool4c output size : \", h.data.size(), ' -> 1/16')\n",
    "\n",
    "        h = self.upscore_pool4(h)\n",
    "        upscore_pool4 = h  # 1/8\n",
    "        #print(\"upscore_pool4(upscore2 + score_pool4c) output size : \", h.data.size(), ' -> 1/8')\n",
    "\n",
    "        h = self.score_pool3(pool3)\n",
    "        #print(\"score_pool3(pool3) output size : \", h.data.size(), ' -> 1/8')\n",
    "        \n",
    "        h = h[:, :,\n",
    "              9:9 + upscore_pool4.size()[2],\n",
    "              9:9 + upscore_pool4.size()[3]]\n",
    "        score_pool3c = h  # 1/8\n",
    "        #print(\"score_pool3c = h[9 : 9+upscore_pool4.size()] output size : \", h.data.size(), ' -> 1/8')\n",
    "\n",
    "        h = upscore_pool4 + score_pool3c  # 1/8\n",
    "        #print(\"upscore_pool4 + score_pool3c output size : \", h.data.size(), ' -> 1/8')\n",
    "        \n",
    "        #h = self.upscore8(h)\n",
    "        #print(\"upscore8 output size : \", h.data.size(), ' -> 1')\n",
    "        \n",
    "        #h = h[:, :, 2:2 + x.size()[2], 2:2 + x.size()[3]].contiguous()\n",
    "        #print(\"h[2 : 2+input.size()] output size : \", h.data.size(), ' -> 1')\n",
    "\n",
    "        return h\n",
    "    \n",
    "    def copy_params_from_vgg16(self, vgg16):\n",
    "        features = [\n",
    "            self.conv1_1, self.relu1_1,\n",
    "            self.conv1_2, self.relu1_2,\n",
    "            self.pool1,\n",
    "            self.conv2_1, self.relu2_1,\n",
    "            self.conv2_2, self.relu2_2,\n",
    "            self.pool2,\n",
    "            self.conv3_1, self.relu3_1,\n",
    "            self.conv3_2, self.relu3_2,\n",
    "            self.conv3_3, self.relu3_3,\n",
    "            self.pool3,\n",
    "            self.conv4_1, self.relu4_1,\n",
    "            self.conv4_2, self.relu4_2,\n",
    "            self.conv4_3, self.relu4_3,\n",
    "            self.pool4,\n",
    "            self.conv5_1, self.relu5_1,\n",
    "            self.conv5_2, self.relu5_2,\n",
    "            self.conv5_3, self.relu5_3,\n",
    "            self.pool5,\n",
    "        ]\n",
    "        for l1, l2 in zip(vgg16.features, features):\n",
    "            if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n",
    "                assert l1.weight.size() == l2.weight.size()\n",
    "                assert l1.bias.size() == l2.bias.size()\n",
    "                l2.weight.data = l1.weight.data\n",
    "                l2.bias.data = l1.bias.data\n",
    "        for i, name in zip([0, 3], ['fc6', 'fc7']):\n",
    "            l1 = vgg16.classifier[i]\n",
    "            l2 = getattr(self, name)\n",
    "            l2.weight.data = l1.weight.data.view(l2.weight.size())\n",
    "            l2.bias.data = l1.bias.data.view(l2.bias.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /Users/LinboHe/.torch/models/vgg16-397923af.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.container.Sequential'>\n",
      "<class 'torch.nn.modules.conv.Conv2d'>\n",
      "torch.Size([256, 256, 3, 3])\n",
      "------------------------copy params to fc6 and fc7------------------------------------\n",
      "l2 fcn32 weight size :  torch.Size([4096, 512, 7, 7])\n",
      "l1 vgg16 weight size :  torch.Size([4096, 25088])\n",
      "------------------------copy params to fc6 and fc7------------------------------------\n",
      "l2 fcn32 weight size :  torch.Size([4096, 4096, 1, 1])\n",
      "l1 vgg16 weight size :  torch.Size([4096, 4096])\n"
     ]
    }
   ],
   "source": [
    "print(type(vgg16_pretrained.features))\n",
    "print(type(vgg16_pretrained.features[12]))\n",
    "print(vgg16_pretrained.features[12].weight.size())\n",
    "vgg16_dict = vgg16_pretrained.state_dict()\n",
    "\n",
    "fcn32s = FCN32s()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_upsampling_weight(in_channels, out_channels, kernel_size):\n",
    "    \"\"\"Make a 2D bilinear kernel suitable for upsampling\"\"\"\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size),\n",
    "                      dtype=np.float64)\n",
    "    weight[range(in_channels), range(out_channels), :, :] = filt\n",
    "    return torch.from_numpy(weight).float()\n",
    "\n",
    "\n",
    "class FCN32s(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class=21, pretrained=False, vgg=None):\n",
    "        super(FCN32s, self).__init__()\n",
    "        # conv1\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=100)\n",
    "        self.relu1_1 = nn.ReLU(inplace=True)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.relu1_2 = nn.ReLU(inplace=True)\n",
    "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/2\n",
    "\n",
    "        # conv2\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.relu2_1 = nn.ReLU(inplace=True)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.relu2_2 = nn.ReLU(inplace=True)\n",
    "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/4\n",
    "\n",
    "        # conv3\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.relu3_2 = nn.ReLU(inplace=True)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.relu3_3 = nn.ReLU(inplace=True)\n",
    "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/8\n",
    "\n",
    "        # conv4\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu4_2 = nn.ReLU(inplace=True)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu4_3 = nn.ReLU(inplace=True)\n",
    "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/16\n",
    "\n",
    "        # conv5\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_2 = nn.ReLU(inplace=True)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.relu5_3 = nn.ReLU(inplace=True)\n",
    "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)  # 1/32\n",
    "\n",
    "        # fc6\n",
    "        self.fc6 = nn.Conv2d(512, 4096, 7)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.drop6 = nn.Dropout2d()\n",
    "\n",
    "        # fc7\n",
    "        self.fc7 = nn.Conv2d(4096, 4096, 1)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.drop7 = nn.Dropout2d()\n",
    "\n",
    "        self.score_fr = nn.Conv2d(4096, n_class, 1)\n",
    "        self.upscore = nn.ConvTranspose2d(n_class, n_class, 64, stride=32,\n",
    "                                          bias=False)\n",
    "\n",
    "        self._initialize_weights()\n",
    "        if pretrained:\n",
    "            self.copy_params_from_vgg16(vgg)\n",
    "            torch.nn.init.xavier_uniform(self.score_fr.weight)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.weight.data.zero_()\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            if isinstance(m, nn.ConvTranspose2d):\n",
    "                assert m.kernel_size[0] == m.kernel_size[1]\n",
    "                initial_weight = get_upsampling_weight(\n",
    "                    m.in_channels, m.out_channels, m.kernel_size[0])\n",
    "                m.weight.data.copy_(initial_weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        print(\"input size : \", h.data.size())\n",
    "        print(\"value: \", h[0][0][0][:3])\n",
    "        h = self.relu1_1(self.conv1_1(h))\n",
    "        print(\"conv1_1 output size : \", h.data.size(), \" -> 1\")\n",
    "        h = self.relu1_2(self.conv1_2(h))\n",
    "        h = self.pool1(h)\n",
    "        print(\"conv1 output size : \", h.data.size(), \" -> 1/2\")\n",
    "        print(\"value: \", h[0][0][0][:3])\n",
    "\n",
    "        h = self.relu2_1(self.conv2_1(h))\n",
    "        h = self.relu2_2(self.conv2_2(h))\n",
    "        h = self.pool2(h)\n",
    "        print(\"conv2 output size : \", h.data.size(), \" -> 1/4\")\n",
    "        print(\"value: \", h[0][0][0][:3])\n",
    "\n",
    "        h = self.relu3_1(self.conv3_1(h))\n",
    "        h = self.relu3_2(self.conv3_2(h))\n",
    "        h = self.relu3_3(self.conv3_3(h))\n",
    "        h = self.pool3(h)\n",
    "        print(\"conv3 output size : \", h.data.size(), \" -> 1/8\")\n",
    "        print(\"value: \", h[0][0][0][:3])\n",
    "\n",
    "        h = self.relu4_1(self.conv4_1(h))\n",
    "        h = self.relu4_2(self.conv4_2(h))\n",
    "        h = self.relu4_3(self.conv4_3(h))\n",
    "        h = self.pool4(h)\n",
    "        print(\"conv4 output size : \", h.data.size(), \" -> 1/16\")\n",
    "        print(\"value: \", h[0][0][0][:3])\n",
    "\n",
    "        h = self.relu5_1(self.conv5_1(h))\n",
    "        h = self.relu5_2(self.conv5_2(h))\n",
    "        h = self.relu5_3(self.conv5_3(h))\n",
    "        h = self.pool5(h)\n",
    "        print(\"conv5 output size : \", h.data.size(), \" -> 1/32\")\n",
    "        print(\"value: \", h[0][0][0][:3])\n",
    "\n",
    "        h = self.relu6(self.fc6(h))\n",
    "        h = self.drop6(h)\n",
    "        print(\"fc6 output size : \", h.data.size())\n",
    "        print(\"value: \", h[0][0][0][:3])\n",
    "\n",
    "        h = self.relu7(self.fc7(h))\n",
    "        h = self.drop7(h)\n",
    "        print(\"fc7 output size : \", h.data.size())\n",
    "        print(\"value: \", h[0][0][0][:3])\n",
    "\n",
    "        h = self.score_fr(h)\n",
    "        print(\"score_fr output size : \", h.data.size(), \" -> prediction for n classes\")\n",
    "\n",
    "        h = self.upscore(h)\n",
    "        print(\"upscore output size : \", h.data.size(), \" -> 1\")\n",
    "\n",
    "        # h = h[:, :, 19:19 + x.size()[2], 19:19 + x.size()[3]].contiguous()\n",
    "        # print(\"with offset 19 output size : \", h.data.size())\n",
    "\n",
    "        h = h[:, :, 30:30 + x.size()[2], 30:30 + x.size()[3]].contiguous()\n",
    "        print(\"with offset 22 output size : \", h.data.size())\n",
    "\n",
    "        return h\n",
    "\n",
    "    def copy_params_from_vgg16(self, vgg16):\n",
    "        features = [\n",
    "            self.conv1_1, self.relu1_1,\n",
    "            self.conv1_2, self.relu1_2,\n",
    "            self.pool1,\n",
    "            self.conv2_1, self.relu2_1,\n",
    "            self.conv2_2, self.relu2_2,\n",
    "            self.pool2,\n",
    "            self.conv3_1, self.relu3_1,\n",
    "            self.conv3_2, self.relu3_2,\n",
    "            self.conv3_3, self.relu3_3,\n",
    "            self.pool3,\n",
    "            self.conv4_1, self.relu4_1,\n",
    "            self.conv4_2, self.relu4_2,\n",
    "            self.conv4_3, self.relu4_3,\n",
    "            self.pool4,\n",
    "            self.conv5_1, self.relu5_1,\n",
    "            self.conv5_2, self.relu5_2,\n",
    "            self.conv5_3, self.relu5_3,\n",
    "            self.pool5,\n",
    "        ]\n",
    "        for l1, l2 in zip(vgg16.features, features):\n",
    "            if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n",
    "                assert l1.weight.size() == l2.weight.size()\n",
    "                assert l1.bias.size() == l2.bias.size()\n",
    "                l2.weight.data = l1.weight.data\n",
    "                l2.bias.data = l1.bias.data\n",
    "        for i, name in zip([0, 3], ['fc6', 'fc7']):\n",
    "            l1 = vgg16.classifier[i]\n",
    "            l2 = getattr(self, name)\n",
    "            l2.weight.data = l1.weight.data.view(l2.weight.size())\n",
    "            l2.bias.data = l1.bias.data.view(l2.bias.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "ThesisWork",
   "language": "python",
   "name": "thesiswork"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
